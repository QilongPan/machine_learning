# sklearn中文教程

## 无监督学习

### 高斯混合模型

## 模型选择和评估

### 交叉验证：评估估计器性能

学习预测函数的参数，并在相同的数据上进行测试，这是一个错误的方法:一个模型如果只是重复它刚刚看到的样本的标签，那么它将获得一个完美的分数，但在尚未看到的数据上，它将无法预测任何有用的东西，这种情况称为过拟合。为了避免这种情况，在执行(监督)机器学习实验时，通常会将部分可用数据作为测试集X_test、y_test。请注意，“实验”这个词并不仅仅指学术用途，因为即使在商业环境中，机器学习通常也是从实验开始的。下面是模型训练中典型的交叉验证工作流流程图。通过网格搜索（grid search）技术可以确定最佳参数。  

![](D:\study resource\code\machine_learning\image\交叉验证流程图.png)

在scikit- learning中，可以使用train_test_split函数快速计算随机分割为训练和测试集的情况。加载iris数据集，拟合其上的线性支持向量机:  

![](D:\study resource\code\machine_learning\image\img1.png)

我们现在可以快速采样一个训练集，同时保留40%的数据来测试(评估)我们的分类器。  

![](D:\study resource\code\machine_learning\image\img2.png)

当为估计器评估不同的设置(超参数)时，例如必须手动为SVM设置c值，测试集仍然存在过度拟合的风险，因为可以调整参数，直到估计器执行最佳。这样，关于测试集的知识就会泄漏到模型中，评估指标就不再报告泛化性能。为了解决这个问题,另一个数据集的一部分可以作为一套所谓验证了:在训练集训练所得,这评价完成后验证集,当实验似乎是成功的,最后的评估可以做测试集。



## sklearn.metrics:Metrics